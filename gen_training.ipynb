{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as pg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import skimage.measure\n",
    "\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "# Globals\n",
    "\n",
    "H = 1600\n",
    "W = 2560 \n",
    "\n",
    "NUM_CROP_W = 82\n",
    "NUM_CROP_H = 86\n",
    "\n",
    "ROUND_CROP_W = 154\n",
    "ROUND_CROP_H = 86\n",
    "\n",
    "numbs_coords = {\n",
    "    0: {\"x\": 122, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "    1: {\"x\": 338, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "    2: {\"x\": 865, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "}\n",
    "wins_coords ={\n",
    "    0: {\"x\": 552, \"y\": 116, \"w\": ROUND_CROP_W, \"h\": ROUND_CROP_H},\n",
    "}\n",
    "\n",
    "\n",
    "# 0 - loading_screen\n",
    "# 1 - name_team\n",
    "# 2 - main_game\n",
    "# 3 - clickthrough\n",
    "# 4 - excess_gold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anifoods = [\n",
    "\"none\",\n",
    "\"empty\",\n",
    "\"ant\",\n",
    "\"apple\",\n",
    "\"badgr\",\n",
    "\"beavr\",\n",
    "\"bfish\",\n",
    "\"bison\",\n",
    "\"boar\",\n",
    "\"camel\",\n",
    "\"can\",\n",
    "\"cat\",\n",
    "\"ccake\",\n",
    "\"chili\",\n",
    "\"choco\",\n",
    "\"cow\",\n",
    "\"crab\",\n",
    "\"crikt\",\n",
    "\"croc\",\n",
    "\"deer\",\n",
    "\"dlphn\",\n",
    "\"dodo\",\n",
    "\"dog\",\n",
    "\"dragn\",\n",
    "\"duck\",\n",
    "\"elpht\",\n",
    "\"fish\",\n",
    "\"fly\",\n",
    "\"garlc\",\n",
    "\"goril\",\n",
    "\"grafe\",\n",
    "\"hghog\",\n",
    "\"hippo\",\n",
    "\"honey\",\n",
    "\"horse\",\n",
    "\"kanga\",\n",
    "\"leprd\",\n",
    "\"mamth\",\n",
    "\"meat\",\n",
    "\"melon\",\n",
    "\"milk\",\n",
    "\"mingo\",\n",
    "\"monky\",\n",
    "\"mosqt\",\n",
    "\"mushm\",\n",
    "\"otter\",\n",
    "\"ox\",\n",
    "\"parrt\",\n",
    "\"pcock\",\n",
    "\"pear\",\n",
    "\"pguin\",\n",
    "\"pig\",\n",
    "\"pill\",\n",
    "\"pizza\",\n",
    "\"rabit\",\n",
    "\"rat\",\n",
    "\"rhino\",\n",
    "\"roost\",\n",
    "\"salad\",\n",
    "\"scorp\",\n",
    "\"seal\",\n",
    "\"shark\",\n",
    "\"sheep\",\n",
    "\"shrmp\",\n",
    "\"skunk\",\n",
    "\"snail\",\n",
    "\"snake\",\n",
    "\"spidr\",\n",
    "\"sqrrl\",\n",
    "\"steak\",\n",
    "\"sushi\",\n",
    "\"swan\",\n",
    "\"tiger\",\n",
    "\"turky\",\n",
    "\"turtl\",\n",
    "\"whale\",\n",
    "\"worm\"\n",
    "]\n",
    "values = range(-1, len(anifoods))\n",
    "\n",
    "anifood_map = dict(zip(anifoods, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def show_cv2_img(window_name, img):\n",
    "    cv2.imshow(window_name, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def img_info(ndarray, gray=0):\n",
    "    '''displays image and shape; gray is a flag used by matplotlib'''\n",
    "    plt.figure(figsize=(18,8))\n",
    "    if gray:\n",
    "        plt.imshow(ndarray, cmap = plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(ndarray);\n",
    "    print('Image shape:', ndarray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = '''\n",
    "Steps for generating data:\n",
    "    read in image,\n",
    "    cut all relevent regions, --> make parameter\n",
    "    for each region,\n",
    "        convert region to BGR,\n",
    "        convert region to greyscale,\n",
    "        standardize region,\n",
    "        print region,\n",
    "        label region,\n",
    "        add region to X,\n",
    "        add label to Y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_files(dir=None):\n",
    "    if dir is None:\n",
    "        file_dir = \"training_base\"\n",
    "    else:\n",
    "        file_dir = dir\n",
    "    # load list of files\n",
    "    file_list = []\n",
    "    for base, dirs, files in os.walk(file_dir):\n",
    "        for f in files:\n",
    "            if not f.startswith(\".\"):\n",
    "                file_list.append(os.path.join(base, f)) \n",
    "    return file_list\n",
    "\n",
    "def int_input(msg):\n",
    "    label = None\n",
    "    try:\n",
    "        label = int(input(msg))\n",
    "        if label in range(-1, 20):\n",
    "            return True, label\n",
    "        else:\n",
    "            return False, -2\n",
    "    except:\n",
    "        return False, -2\n",
    "\n",
    "def get_regions(img, coords):\n",
    "    regions = []\n",
    "    for k, v in coords.items():\n",
    "        x = v[\"x\"]\n",
    "        y = v[\"y\"]\n",
    "        w = v[\"w\"]\n",
    "        h = v[\"h\"]\n",
    "\n",
    "        # Sanity check\n",
    "        # print(f\"(Y: {y}, H: {h})  (X: {x}, W: {w})\")\n",
    "        region = img[y: y + h, x: x + w]\n",
    "        regions.append(region)\n",
    "        \n",
    "        # Sanity check 2\n",
    "        # img_info(region, gray=1)\n",
    "    return regions\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def gen_training(file_list, coords):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        print(f\"File name: {fname}\")\n",
    "        iter += 1\n",
    "        base_img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "        # #TODO: Cut the relevent regions out here, for now just base_img is 1 region\n",
    "        regions = get_regions(base_img, coords)\n",
    "\n",
    "        for img in regions:\n",
    "\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "            # show_cv2_img(\"ORIG\", img)\n",
    "            img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "            # show_cv2_img(\"GRAYSCALE\", img)\n",
    "            img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "            # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "            img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "            # show_cv2_img(\"RESCALED\", img)\n",
    "\n",
    "            # Show region and ask to label\n",
    "            show_cv2_img(f\"Example: {iter}\", img)\n",
    "\n",
    "            # Get user input \n",
    "            isOK, label = int_input(\"\\rLabel? \")\n",
    "            while isOK != True:\n",
    "                print(f\"\\rNOt OK! isOK: {isOK}\")\n",
    "                print(f\"\\rlabel is: {label}\")\n",
    "                isOK, label = int_input(\"\\rMust be int range(0, 20) Label?: \")\n",
    " \n",
    "            if label == -1:\n",
    "                print(\"Okay! We're done here.\")\n",
    "                print(f\"X is:\\n{X}\")\n",
    "                print(f\"y is:\\n{y}\")\n",
    "                return None, None\n",
    "\n",
    "            \n",
    "            print(\"\\rAdding to X and y...\")\n",
    "            if y is None:\n",
    "                y = np.array(label)\n",
    "            else:\n",
    "                y = np.append(y, label)\n",
    "\n",
    "            if X is None:\n",
    "                X = np.array(img.flatten())\n",
    "            else:\n",
    "                X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def add_win_training(file_list, coords):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    total = len(flist)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        ftype = os.path.basename(fname).split(\"_\")[0]\n",
    "        if ftype != \"lives\":\n",
    "            continue\n",
    "\n",
    "        iter += 1\n",
    "        print(f\"Iter: {iter}/{total}\")\n",
    "        base_img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "        # #TODO: Cut the relevent regions out here, for now just base_img is 1 region\n",
    "        regions = get_regions(base_img, coords)\n",
    "\n",
    "        for img in regions:\n",
    "\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "            # show_cv2_img(\"ORIG\", img)\n",
    "            img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "            # show_cv2_img(\"GRAYSCALE\", img)\n",
    "            img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "            # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "            img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "            # show_cv2_img(\"RESCALED\", img)\n",
    "\n",
    "            label = 9\n",
    "\n",
    "            \n",
    "            print(\"\\rAdding to X and y...\")\n",
    "            if y is None:\n",
    "                y = np.array(label)\n",
    "            else:\n",
    "                y = np.append(y, label)\n",
    "\n",
    "            if X is None:\n",
    "                X = np.array(img.flatten())\n",
    "            else:\n",
    "                X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "def gen_situation_training(file_list):\n",
    "    # 0 - LOADING\n",
    "# 1 - NAME TEAM\n",
    "# 2 - MAIN GAME\n",
    "# 3 - CLICK THROUGH\n",
    "# 4 - EXCESS GOLD1\n",
    "\n",
    "    label_map = dict(\n",
    "        loading      = 0,\n",
    "        name         = 1,\n",
    "        main         = 2,\n",
    "        clickthrough = 3,\n",
    "        excess       = 4\n",
    "    )\n",
    "\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        print(f\"File name: {fname}\")\n",
    "        iter += 1\n",
    "        print(f\"iter {iter}/{todo}\")\n",
    "        if iter == 500:\n",
    "            break\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        # show_cv2_img(\"ORIG\", img)\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        # show_cv2_img(\"GRAYSCALE\", img)\n",
    "        img = skimage.measure.block_reduce(img, (8,8), np.max)  # Downsample\n",
    "        # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        print(img.shape)\n",
    "\n",
    "        file_lname = os.path.basename(fname).split(\"_\")[0]\n",
    "        label = label_map[file_lname]\n",
    "        \n",
    "        print(f\"Adding to X and y. label - {file_lname}: {label}\")\n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_numb_training2(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        label = int(os.path.basename(fname).split(\"_\")[0])\n",
    "        iter += 1\n",
    "        print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        # # show_cv2_img(\"ORIG\", img)\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        # # show_cv2_img(\"GRAYSCALE\", img)\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        # # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        # # print(img.shape)\n",
    "\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_anifood_training(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        aniname = os.path.basename(fname).split(\"_\")[0]\n",
    "        label = anifood_map[aniname]\n",
    "        # print(f\"{aniname}: {label}\")\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_attack_or_health_training(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        label = int(os.path.basename(fname).split(\"_\")[0])\n",
    "        # label = anifood_map[aniname]\n",
    "        # print(f\"Label: {label}\")\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = load_files(\"health_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_attack_or_health_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = load_files(\"attack_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_attack_or_health_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = load_files(\"anifood_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_anifood_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the NUMBS AI\n",
    "flist = load_files(\"numbs_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_numb_training2(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Situation AI\n",
    "flist = load_files(\"situation_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_situation_training(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the WINS AI\n",
    "flist = load_files()\n",
    "print(len(flist))\n",
    "X, y = gen_training(flist, wins_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to WINS AI\n",
    "flist = load_files()\n",
    "print(len(flist))\n",
    "X, y = add_win_training(flist, wins_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some initial stats about X and y\n",
    "def print_counts(y):\n",
    "    vals, counts = np.unique(y, return_counts=True)\n",
    "    for val, count in zip(vals, counts):\n",
    "        print(f\"Val: {val}, Count: {count}\")\n",
    "\n",
    "# NOTE:\n",
    "# Weak number in NUMBS that need a boost!  i.e. < 60 examples\n",
    "# [0, 1, 2, 4, 5, 8, 11, 12, 13, 14]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training data to disk\n",
    "\n",
    "ml_data = \"ml_data\"\n",
    "np.savetxt(os.path.join(ml_data, \"health_x_train.txt\"), X)\n",
    "np.savetxt(os.path.join(ml_data, \"health_y_train.txt\"), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 5 candidates, totalling 75 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=9'>10</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=10'>11</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=11'>12</a>\u001b[0m     estimator\u001b[39m=\u001b[39mmodel, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=12'>13</a>\u001b[0m     param_grid\u001b[39m=\u001b[39mgrid, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=17'>18</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=18'>19</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mchamplin/Documents/projects/superAIpets/gen_training.ipynb#ch0000013?line=19'>20</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=435'>436</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=438'>439</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=440'>441</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=299'>300</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=300'>301</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=301'>302</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=302'>303</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/Cellar/python%403.8/3.8.13/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py?line=303'>304</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION STUFFSSS\n",
    "\n",
    "model = LogisticRegression(multi_class=\"multinomial\", max_iter=400)\n",
    "solvers = ['lbfgs']\n",
    "penalty = ['l2']\n",
    "c_values = np.logspace(-2,0,5)\n",
    "\n",
    "# # define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=grid, \n",
    "    n_jobs=-1, \n",
    "    cv=cv, \n",
    "    scoring='accuracy',\n",
    "    error_score=0, \n",
    "    verbose=4,\n",
    ")\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means  = grid_result.cv_results_['mean_test_score']\n",
    "stds   = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "# Best: 0.998788 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "\n",
    "# L2_grid_search_df = pd.DataFrame.from_dict(grid_result.cv_results_)\n",
    "# L2_grid_search_df.to_csv(\"result_csvs/L2_grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "# X = np.loadtxt(os.path.join(\"ml_data\", \"wins_x_train.txt\"))\n",
    "# y = np.loadtxt(os.path.join(\"ml_data\", \"wins_y_train.txt\"))\n",
    "best_numbs_model = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    C=0.01,\n",
    "    max_iter=400\n",
    "    )\n",
    "\n",
    "best_numbs_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_numbs_model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try MLP\n",
    "\n",
    "# Things to modify\n",
    "# * Alpha for sure\n",
    "# * Random state, since class\n",
    "# * Activation function \n",
    "\n",
    "# X = np.loadtxt(os.path.join(\"ml_data\", \"numbs_x_train.txt\"))\n",
    "# y = np.loadtxt(os.path.join(\"ml_data\", \"numbs_y_train.txt\"))\n",
    "\n",
    "# print_counts(y)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model         = MLPClassifier(max_iter=500)\n",
    "mlp_solver        = ['lbfgs']\n",
    "# mlp_random_states = [1,2,3,4,5]\n",
    "mlp_activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "alphas = np.logspace(-2, 0, 5)\n",
    "\n",
    "# define grid search\n",
    "mlp_grid = dict(\n",
    "    solver=mlp_solver,\n",
    "    # random_state=mlp_random_states, \n",
    "    activation=mlp_activation_functions, \n",
    "    alpha=alphas, \n",
    ")\n",
    "mlp_cv          = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "mlp_grid_search = GridSearchCV(\n",
    "    estimator=mlp_model, \n",
    "    param_grid=mlp_grid, \n",
    "    n_jobs=-1, \n",
    "    cv=mlp_cv, \n",
    "    scoring='accuracy',\n",
    "    error_score=0,\n",
    "    verbose=4\n",
    ")\n",
    "mlp_grid_result = mlp_grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (mlp_grid_result.best_score_, mlp_grid_result.best_params_))\n",
    "means  = mlp_grid_result.cv_results_['mean_test_score']\n",
    "stds   = mlp_grid_result.cv_results_['std_test_score']\n",
    "params = mlp_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Final Best MLP Model\n",
    "# Best: 0.998788 using {'activation': 'logistic', 'alpha': 0.01, 'random_state': 1, 'solver': 'lbfgs'}\n",
    "best_MLP = MLPClassifier(\n",
    "    activation   = \"logistic\",\n",
    "    alpha        = 0.01,\n",
    "    random_state = 1,\n",
    "    solver       = \"lbfgs\",\n",
    "    max_iter     = 500\n",
    "    )\n",
    "\n",
    "best_MLP.fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = best_MLP.score(X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = best_MLP.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, group in enumerate(zip(y, predy)):\n",
    "    if group[0] != group[1]:\n",
    "        print(f\"Pic #: {i}, Actual: {group[0]}, Pred: {group[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = os.path.join(\"models\", \"health_MLP_model.01\")\n",
    "pickle.dump(best_numbs_model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X[0:100], y[:100])\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testx = np.loadtxt(os.path.join(\"ml_data\", \"numbs_x_train.txt\"))\n",
    "# testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GET COORDS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the coords for each attribute\n",
    "# find in specific order:\n",
    "# [coins, lives, wins, round]\n",
    "# info_img_dir = \"find_info_imgs\"\n",
    "\n",
    "# coins_file = os.path.join(info_img_dir, \"coins.png\")\n",
    "# lives_file = os.path.join(info_img_dir, \"lives.png\")\n",
    "# wins_file  = os.path.join(info_img_dir, \"wins.png\")\n",
    "# round_file = os.path.join(info_img_dir, \"round.png\")\n",
    "\n",
    "# base_file  = os.path.join(info_img_dir, \"base_w_squares.png\")\n",
    "\n",
    "# target_files = [coins_file, lives_file, wins_file, round_file]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i, t in enumerate(target_files):\n",
    "#     base_img = cv2.imread(base_file, cv2.COLOR_RGB2BGR)\n",
    "#     search_img = cv2.imread(t, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     if i != 2:\n",
    "#         w = NUM_CROP_W\n",
    "#         h = NUM_CROP_H\n",
    "#     else:\n",
    "#         w = ROUND_CROP_W\n",
    "#         h = ROUND_CROP_H\n",
    "\n",
    "#     a, b, c, best_match_xy = cv2.minMaxLoc(cv2.matchTemplate(base_img, search_img, cv2.TM_CCOEFF_NORMED))\n",
    "#     print(a, b, c, best_match_xy)\n",
    "#     cv2.rectangle(base_img, (best_match_xy[0], best_match_xy[1]), (best_match_xy[0] + w, best_match_xy[1] + h), (0,255,255), 2)\n",
    "#     show_cv2_img(\"bleh\", base_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(122, 116)\n",
    "(338, 116)\n",
    "(552, 116)\n",
    "(865, 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
