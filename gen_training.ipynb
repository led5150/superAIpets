{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as pg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import skimage.measure\n",
    "\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "# Globals\n",
    "\n",
    "H = 1600\n",
    "W = 2560 \n",
    "\n",
    "NUM_CROP_W = 82\n",
    "NUM_CROP_H = 86\n",
    "\n",
    "ROUND_CROP_W = 154\n",
    "ROUND_CROP_H = 86\n",
    "\n",
    "numbs_coords = {\n",
    "    0: {\"x\": 122, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "    1: {\"x\": 338, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "    2: {\"x\": 865, \"y\": 116, \"w\": NUM_CROP_W, \"h\": NUM_CROP_H},\n",
    "}\n",
    "wins_coords ={\n",
    "    0: {\"x\": 552, \"y\": 116, \"w\": ROUND_CROP_W, \"h\": ROUND_CROP_H},\n",
    "}\n",
    "\n",
    "\n",
    "# 0 - loading_screen\n",
    "# 1 - name_team\n",
    "# 2 - main_game\n",
    "# 3 - clickthrough\n",
    "# 4 - excess_gold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anifoods = [\n",
    "\"none\",\n",
    "\"empty\",\n",
    "\"ant\",\n",
    "\"apple\",\n",
    "\"badgr\",\n",
    "\"beavr\",\n",
    "\"bfish\",\n",
    "\"bison\",\n",
    "\"boar\",\n",
    "\"camel\",\n",
    "\"can\",\n",
    "\"cat\",\n",
    "\"ccake\",\n",
    "\"chili\",\n",
    "\"choco\",\n",
    "\"cow\",\n",
    "\"crab\",\n",
    "\"crikt\",\n",
    "\"croc\",\n",
    "\"deer\",\n",
    "\"dlphn\",\n",
    "\"dodo\",\n",
    "\"dog\",\n",
    "\"dragn\",\n",
    "\"duck\",\n",
    "\"elpht\",\n",
    "\"fish\",\n",
    "\"fly\",\n",
    "\"garlc\",\n",
    "\"goril\",\n",
    "\"grafe\",\n",
    "\"hghog\",\n",
    "\"hippo\",\n",
    "\"honey\",\n",
    "\"horse\",\n",
    "\"kanga\",\n",
    "\"leprd\",\n",
    "\"mamth\",\n",
    "\"meat\",\n",
    "\"melon\",\n",
    "\"milk\",\n",
    "\"mingo\",\n",
    "\"monky\",\n",
    "\"mosqt\",\n",
    "\"mushm\",\n",
    "\"otter\",\n",
    "\"ox\",\n",
    "\"parrt\",\n",
    "\"pcock\",\n",
    "\"pear\",\n",
    "\"pguin\",\n",
    "\"pig\",\n",
    "\"pill\",\n",
    "\"pizza\",\n",
    "\"rabit\",\n",
    "\"rat\",\n",
    "\"rhino\",\n",
    "\"roost\",\n",
    "\"salad\",\n",
    "\"scorp\",\n",
    "\"seal\",\n",
    "\"shark\",\n",
    "\"sheep\",\n",
    "\"shrmp\",\n",
    "\"skunk\",\n",
    "\"snail\",\n",
    "\"snake\",\n",
    "\"spidr\",\n",
    "\"sqrrl\",\n",
    "\"steak\",\n",
    "\"sushi\",\n",
    "\"swan\",\n",
    "\"tiger\",\n",
    "\"turky\",\n",
    "\"turtl\",\n",
    "\"whale\",\n",
    "\"worm\"\n",
    "]\n",
    "values = range(-1, len(anifoods))\n",
    "\n",
    "anifood_map = dict(zip(anifoods, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def show_cv2_img(window_name, img):\n",
    "    cv2.imshow(window_name, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def img_info(ndarray, gray=0):\n",
    "    '''displays image and shape; gray is a flag used by matplotlib'''\n",
    "    plt.figure(figsize=(18,8))\n",
    "    if gray:\n",
    "        plt.imshow(ndarray, cmap = plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(ndarray);\n",
    "    print('Image shape:', ndarray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = '''\n",
    "Steps for generating data:\n",
    "    read in image,\n",
    "    cut all relevent regions, --> make parameter\n",
    "    for each region,\n",
    "        convert region to BGR,\n",
    "        convert region to greyscale,\n",
    "        standardize region,\n",
    "        print region,\n",
    "        label region,\n",
    "        add region to X,\n",
    "        add label to Y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_files(dir=None):\n",
    "    if dir is None:\n",
    "        file_dir = \"training_base\"\n",
    "    else:\n",
    "        file_dir = dir\n",
    "    # load list of files\n",
    "    file_list = []\n",
    "    for base, dirs, files in os.walk(file_dir):\n",
    "        for f in files:\n",
    "            if not f.startswith(\".\"):\n",
    "                file_list.append(os.path.join(base, f)) \n",
    "    return file_list\n",
    "\n",
    "def int_input(msg):\n",
    "    label = None\n",
    "    try:\n",
    "        label = int(input(msg))\n",
    "        if label in range(-1, 20):\n",
    "            return True, label\n",
    "        else:\n",
    "            return False, -2\n",
    "    except:\n",
    "        return False, -2\n",
    "\n",
    "def get_regions(img, coords):\n",
    "    regions = []\n",
    "    for k, v in coords.items():\n",
    "        x = v[\"x\"]\n",
    "        y = v[\"y\"]\n",
    "        w = v[\"w\"]\n",
    "        h = v[\"h\"]\n",
    "\n",
    "        # Sanity check\n",
    "        # print(f\"(Y: {y}, H: {h})  (X: {x}, W: {w})\")\n",
    "        region = img[y: y + h, x: x + w]\n",
    "        regions.append(region)\n",
    "        \n",
    "        # Sanity check 2\n",
    "        # img_info(region, gray=1)\n",
    "    return regions\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def gen_training(file_list, coords):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        print(f\"File name: {fname}\")\n",
    "        iter += 1\n",
    "        base_img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "        # #TODO: Cut the relevent regions out here, for now just base_img is 1 region\n",
    "        regions = get_regions(base_img, coords)\n",
    "\n",
    "        for img in regions:\n",
    "\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "            # show_cv2_img(\"ORIG\", img)\n",
    "            img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "            # show_cv2_img(\"GRAYSCALE\", img)\n",
    "            img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "            # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "            img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "            # show_cv2_img(\"RESCALED\", img)\n",
    "\n",
    "            # Show region and ask to label\n",
    "            show_cv2_img(f\"Example: {iter}\", img)\n",
    "\n",
    "            # Get user input \n",
    "            isOK, label = int_input(\"\\rLabel? \")\n",
    "            while isOK != True:\n",
    "                print(f\"\\rNOt OK! isOK: {isOK}\")\n",
    "                print(f\"\\rlabel is: {label}\")\n",
    "                isOK, label = int_input(\"\\rMust be int range(0, 20) Label?: \")\n",
    " \n",
    "            if label == -1:\n",
    "                print(\"Okay! We're done here.\")\n",
    "                print(f\"X is:\\n{X}\")\n",
    "                print(f\"y is:\\n{y}\")\n",
    "                return None, None\n",
    "\n",
    "            \n",
    "            print(\"\\rAdding to X and y...\")\n",
    "            if y is None:\n",
    "                y = np.array(label)\n",
    "            else:\n",
    "                y = np.append(y, label)\n",
    "\n",
    "            if X is None:\n",
    "                X = np.array(img.flatten())\n",
    "            else:\n",
    "                X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def add_win_training(file_list, coords):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    total = len(flist)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        ftype = os.path.basename(fname).split(\"_\")[0]\n",
    "        if ftype != \"lives\":\n",
    "            continue\n",
    "\n",
    "        iter += 1\n",
    "        print(f\"Iter: {iter}/{total}\")\n",
    "        base_img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "        # #TODO: Cut the relevent regions out here, for now just base_img is 1 region\n",
    "        regions = get_regions(base_img, coords)\n",
    "\n",
    "        for img in regions:\n",
    "\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "            # show_cv2_img(\"ORIG\", img)\n",
    "            img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "            # show_cv2_img(\"GRAYSCALE\", img)\n",
    "            img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "            # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "            img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "            # show_cv2_img(\"RESCALED\", img)\n",
    "\n",
    "            label = 9\n",
    "\n",
    "            \n",
    "            print(\"\\rAdding to X and y...\")\n",
    "            if y is None:\n",
    "                y = np.array(label)\n",
    "            else:\n",
    "                y = np.append(y, label)\n",
    "\n",
    "            if X is None:\n",
    "                X = np.array(img.flatten())\n",
    "            else:\n",
    "                X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "def gen_situation_training(file_list):\n",
    "    # 0 - LOADING\n",
    "# 1 - NAME TEAM\n",
    "# 2 - MAIN GAME\n",
    "# 3 - CLICK THROUGH\n",
    "# 4 - EXCESS GOLD1\n",
    "\n",
    "    label_map = dict(\n",
    "        loading      = 0,\n",
    "        name         = 1,\n",
    "        main         = 2,\n",
    "        clickthrough = 3,\n",
    "        excess       = 4\n",
    "    )\n",
    "\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        print(f\"File name: {fname}\")\n",
    "        iter += 1\n",
    "        print(f\"iter {iter}/{todo}\")\n",
    "        if iter == 500:\n",
    "            break\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        # show_cv2_img(\"ORIG\", img)\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        # show_cv2_img(\"GRAYSCALE\", img)\n",
    "        img = skimage.measure.block_reduce(img, (8,8), np.max)  # Downsample\n",
    "        # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        print(img.shape)\n",
    "\n",
    "        file_lname = os.path.basename(fname).split(\"_\")[0]\n",
    "        label = label_map[file_lname]\n",
    "        \n",
    "        print(f\"Adding to X and y. label - {file_lname}: {label}\")\n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_numb_training2(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        label = int(os.path.basename(fname).split(\"_\")[0])\n",
    "        iter += 1\n",
    "        print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        # # show_cv2_img(\"ORIG\", img)\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        # # show_cv2_img(\"GRAYSCALE\", img)\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        # # show_cv2_img(\"DOWNSAMPLE\", img)\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        # # print(img.shape)\n",
    "\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_anifood_training(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        aniname = os.path.basename(fname).split(\"_\")[0]\n",
    "        label = anifood_map[aniname]\n",
    "        # print(f\"{aniname}: {label}\")\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_attack_or_health_training(file_list):\n",
    "    # Output arrays for training data\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    iter = 0\n",
    "    todo = len(file_list)\n",
    "    # iterate over all files and classify them\n",
    "    for fname in file_list:\n",
    "        label = int(os.path.basename(fname).split(\"_\")[0])\n",
    "        # label = anifood_map[aniname]\n",
    "        # print(f\"Label: {label}\")\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            print(f\"iter {iter}/{todo}\")\n",
    "\n",
    "        img = cv2.imread(fname, cv2.COLOR_RGB2BGR)    # read in base img from file\n",
    "        \n",
    "\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)    # Convert to BGR\n",
    "        img = np.dot(img, [0.2989, 0.5870, 0.1140])             # Convert to grayscale\n",
    "        img = skimage.measure.block_reduce(img, (2,2), np.max)  # Downsample\n",
    "        img = (img - img.mean()) / np.sqrt(img.var() + 1e-5)    # Rescale\n",
    "        # show_cv2_img(\"RESCALED\", img)\n",
    "        \n",
    "        if y is None:\n",
    "            y = np.array(label)\n",
    "        else:\n",
    "            y = np.append(y, label)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.array(img.flatten())\n",
    "        else:\n",
    "            X = np.vstack((X, img.flatten()))\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11050\n",
      "iter 50/11050\n",
      "iter 100/11050\n",
      "iter 150/11050\n",
      "iter 200/11050\n",
      "iter 250/11050\n",
      "iter 300/11050\n",
      "iter 350/11050\n",
      "iter 400/11050\n",
      "iter 450/11050\n",
      "iter 500/11050\n",
      "iter 550/11050\n",
      "iter 600/11050\n",
      "iter 650/11050\n",
      "iter 700/11050\n",
      "iter 750/11050\n",
      "iter 800/11050\n",
      "iter 850/11050\n",
      "iter 900/11050\n",
      "iter 950/11050\n",
      "iter 1000/11050\n",
      "iter 1050/11050\n",
      "iter 1100/11050\n",
      "iter 1150/11050\n",
      "iter 1200/11050\n",
      "iter 1250/11050\n",
      "iter 1300/11050\n",
      "iter 1350/11050\n",
      "iter 1400/11050\n",
      "iter 1450/11050\n",
      "iter 1500/11050\n",
      "iter 1550/11050\n",
      "iter 1600/11050\n",
      "iter 1650/11050\n",
      "iter 1700/11050\n",
      "iter 1750/11050\n",
      "iter 1800/11050\n",
      "iter 1850/11050\n",
      "iter 1900/11050\n",
      "iter 1950/11050\n",
      "iter 2000/11050\n",
      "iter 2050/11050\n",
      "iter 2100/11050\n",
      "iter 2150/11050\n",
      "iter 2200/11050\n",
      "iter 2250/11050\n",
      "iter 2300/11050\n",
      "iter 2350/11050\n",
      "iter 2400/11050\n",
      "iter 2450/11050\n",
      "iter 2500/11050\n",
      "iter 2550/11050\n",
      "iter 2600/11050\n",
      "iter 2650/11050\n",
      "iter 2700/11050\n",
      "iter 2750/11050\n",
      "iter 2800/11050\n",
      "iter 2850/11050\n",
      "iter 2900/11050\n",
      "iter 2950/11050\n",
      "iter 3000/11050\n",
      "iter 3050/11050\n",
      "iter 3100/11050\n",
      "iter 3150/11050\n",
      "iter 3200/11050\n",
      "iter 3250/11050\n",
      "iter 3300/11050\n",
      "iter 3350/11050\n",
      "iter 3400/11050\n",
      "iter 3450/11050\n",
      "iter 3500/11050\n",
      "iter 3550/11050\n",
      "iter 3600/11050\n",
      "iter 3650/11050\n",
      "iter 3700/11050\n",
      "iter 3750/11050\n",
      "iter 3800/11050\n",
      "iter 3850/11050\n",
      "iter 3900/11050\n",
      "iter 3950/11050\n",
      "iter 4000/11050\n",
      "iter 4050/11050\n",
      "iter 4100/11050\n",
      "iter 4150/11050\n",
      "iter 4200/11050\n",
      "iter 4250/11050\n",
      "iter 4300/11050\n",
      "iter 4350/11050\n",
      "iter 4400/11050\n",
      "iter 4450/11050\n",
      "iter 4500/11050\n",
      "iter 4550/11050\n",
      "iter 4600/11050\n",
      "iter 4650/11050\n",
      "iter 4700/11050\n",
      "iter 4750/11050\n",
      "iter 4800/11050\n",
      "iter 4850/11050\n",
      "iter 4900/11050\n",
      "iter 4950/11050\n",
      "iter 5000/11050\n",
      "iter 5050/11050\n",
      "iter 5100/11050\n",
      "iter 5150/11050\n",
      "iter 5200/11050\n",
      "iter 5250/11050\n",
      "iter 5300/11050\n",
      "iter 5350/11050\n",
      "iter 5400/11050\n",
      "iter 5450/11050\n",
      "iter 5500/11050\n",
      "iter 5550/11050\n",
      "iter 5600/11050\n",
      "iter 5650/11050\n",
      "iter 5700/11050\n",
      "iter 5750/11050\n",
      "iter 5800/11050\n",
      "iter 5850/11050\n",
      "iter 5900/11050\n",
      "iter 5950/11050\n",
      "iter 6000/11050\n",
      "iter 6050/11050\n",
      "iter 6100/11050\n",
      "iter 6150/11050\n",
      "iter 6200/11050\n",
      "iter 6250/11050\n",
      "iter 6300/11050\n",
      "iter 6350/11050\n",
      "iter 6400/11050\n",
      "iter 6450/11050\n",
      "iter 6500/11050\n",
      "iter 6550/11050\n",
      "iter 6600/11050\n",
      "iter 6650/11050\n",
      "iter 6700/11050\n",
      "iter 6750/11050\n",
      "iter 6800/11050\n",
      "iter 6850/11050\n",
      "iter 6900/11050\n",
      "iter 6950/11050\n",
      "iter 7000/11050\n",
      "iter 7050/11050\n",
      "iter 7100/11050\n",
      "iter 7150/11050\n",
      "iter 7200/11050\n",
      "iter 7250/11050\n",
      "iter 7300/11050\n",
      "iter 7350/11050\n",
      "iter 7400/11050\n",
      "iter 7450/11050\n",
      "iter 7500/11050\n",
      "iter 7550/11050\n",
      "iter 7600/11050\n",
      "iter 7650/11050\n",
      "iter 7700/11050\n",
      "iter 7750/11050\n",
      "iter 7800/11050\n",
      "iter 7850/11050\n",
      "iter 7900/11050\n",
      "iter 7950/11050\n",
      "iter 8000/11050\n",
      "iter 8050/11050\n",
      "iter 8100/11050\n",
      "iter 8150/11050\n",
      "iter 8200/11050\n",
      "iter 8250/11050\n",
      "iter 8300/11050\n",
      "iter 8350/11050\n",
      "iter 8400/11050\n",
      "iter 8450/11050\n",
      "iter 8500/11050\n",
      "iter 8550/11050\n",
      "iter 8600/11050\n",
      "iter 8650/11050\n",
      "iter 8700/11050\n",
      "iter 8750/11050\n",
      "iter 8800/11050\n",
      "iter 8850/11050\n",
      "iter 8900/11050\n",
      "iter 8950/11050\n",
      "iter 9000/11050\n",
      "iter 9050/11050\n",
      "iter 9100/11050\n",
      "iter 9150/11050\n",
      "iter 9200/11050\n",
      "iter 9250/11050\n",
      "iter 9300/11050\n",
      "iter 9350/11050\n",
      "iter 9400/11050\n",
      "iter 9450/11050\n",
      "iter 9500/11050\n",
      "iter 9550/11050\n",
      "iter 9600/11050\n",
      "iter 9650/11050\n",
      "iter 9700/11050\n",
      "iter 9750/11050\n",
      "iter 9800/11050\n",
      "iter 9850/11050\n",
      "iter 9900/11050\n",
      "iter 9950/11050\n",
      "iter 10000/11050\n",
      "iter 10050/11050\n",
      "iter 10100/11050\n",
      "iter 10150/11050\n",
      "iter 10200/11050\n",
      "iter 10250/11050\n",
      "iter 10300/11050\n",
      "iter 10350/11050\n",
      "iter 10400/11050\n",
      "iter 10450/11050\n",
      "iter 10500/11050\n",
      "iter 10550/11050\n",
      "iter 10600/11050\n",
      "iter 10650/11050\n",
      "iter 10700/11050\n",
      "iter 10750/11050\n",
      "iter 10800/11050\n",
      "iter 10850/11050\n",
      "iter 10900/11050\n",
      "iter 10950/11050\n",
      "iter 11000/11050\n",
      "iter 11050/11050\n"
     ]
    }
   ],
   "source": [
    "flist = load_files(\"health_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_attack_or_health_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10965\n",
      "iter 50/10965\n",
      "iter 100/10965\n",
      "iter 150/10965\n",
      "iter 200/10965\n",
      "iter 250/10965\n",
      "iter 300/10965\n",
      "iter 350/10965\n",
      "iter 400/10965\n",
      "iter 450/10965\n",
      "iter 500/10965\n",
      "iter 550/10965\n",
      "iter 600/10965\n",
      "iter 650/10965\n",
      "iter 700/10965\n",
      "iter 750/10965\n",
      "iter 800/10965\n",
      "iter 850/10965\n",
      "iter 900/10965\n",
      "iter 950/10965\n",
      "iter 1000/10965\n",
      "iter 1050/10965\n",
      "iter 1100/10965\n",
      "iter 1150/10965\n",
      "iter 1200/10965\n",
      "iter 1250/10965\n",
      "iter 1300/10965\n",
      "iter 1350/10965\n",
      "iter 1400/10965\n",
      "iter 1450/10965\n",
      "iter 1500/10965\n",
      "iter 1550/10965\n",
      "iter 1600/10965\n",
      "iter 1650/10965\n",
      "iter 1700/10965\n",
      "iter 1750/10965\n",
      "iter 1800/10965\n",
      "iter 1850/10965\n",
      "iter 1900/10965\n",
      "iter 1950/10965\n",
      "iter 2000/10965\n",
      "iter 2050/10965\n",
      "iter 2100/10965\n",
      "iter 2150/10965\n",
      "iter 2200/10965\n",
      "iter 2250/10965\n",
      "iter 2300/10965\n",
      "iter 2350/10965\n",
      "iter 2400/10965\n",
      "iter 2450/10965\n",
      "iter 2500/10965\n",
      "iter 2550/10965\n",
      "iter 2600/10965\n",
      "iter 2650/10965\n",
      "iter 2700/10965\n",
      "iter 2750/10965\n",
      "iter 2800/10965\n",
      "iter 2850/10965\n",
      "iter 2900/10965\n",
      "iter 2950/10965\n",
      "iter 3000/10965\n",
      "iter 3050/10965\n",
      "iter 3100/10965\n",
      "iter 3150/10965\n",
      "iter 3200/10965\n",
      "iter 3250/10965\n",
      "iter 3300/10965\n",
      "iter 3350/10965\n",
      "iter 3400/10965\n",
      "iter 3450/10965\n",
      "iter 3500/10965\n",
      "iter 3550/10965\n",
      "iter 3600/10965\n",
      "iter 3650/10965\n",
      "iter 3700/10965\n",
      "iter 3750/10965\n",
      "iter 3800/10965\n",
      "iter 3850/10965\n",
      "iter 3900/10965\n",
      "iter 3950/10965\n",
      "iter 4000/10965\n",
      "iter 4050/10965\n",
      "iter 4100/10965\n",
      "iter 4150/10965\n",
      "iter 4200/10965\n",
      "iter 4250/10965\n",
      "iter 4300/10965\n",
      "iter 4350/10965\n",
      "iter 4400/10965\n",
      "iter 4450/10965\n",
      "iter 4500/10965\n",
      "iter 4550/10965\n",
      "iter 4600/10965\n",
      "iter 4650/10965\n",
      "iter 4700/10965\n",
      "iter 4750/10965\n",
      "iter 4800/10965\n",
      "iter 4850/10965\n",
      "iter 4900/10965\n",
      "iter 4950/10965\n",
      "iter 5000/10965\n",
      "iter 5050/10965\n",
      "iter 5100/10965\n",
      "iter 5150/10965\n",
      "iter 5200/10965\n",
      "iter 5250/10965\n",
      "iter 5300/10965\n",
      "iter 5350/10965\n",
      "iter 5400/10965\n",
      "iter 5450/10965\n",
      "iter 5500/10965\n",
      "iter 5550/10965\n",
      "iter 5600/10965\n",
      "iter 5650/10965\n",
      "iter 5700/10965\n",
      "iter 5750/10965\n",
      "iter 5800/10965\n",
      "iter 5850/10965\n",
      "iter 5900/10965\n",
      "iter 5950/10965\n",
      "iter 6000/10965\n",
      "iter 6050/10965\n",
      "iter 6100/10965\n",
      "iter 6150/10965\n",
      "iter 6200/10965\n",
      "iter 6250/10965\n",
      "iter 6300/10965\n",
      "iter 6350/10965\n",
      "iter 6400/10965\n",
      "iter 6450/10965\n",
      "iter 6500/10965\n",
      "iter 6550/10965\n",
      "iter 6600/10965\n",
      "iter 6650/10965\n",
      "iter 6700/10965\n",
      "iter 6750/10965\n",
      "iter 6800/10965\n",
      "iter 6850/10965\n",
      "iter 6900/10965\n",
      "iter 6950/10965\n",
      "iter 7000/10965\n",
      "iter 7050/10965\n",
      "iter 7100/10965\n",
      "iter 7150/10965\n",
      "iter 7200/10965\n",
      "iter 7250/10965\n",
      "iter 7300/10965\n",
      "iter 7350/10965\n",
      "iter 7400/10965\n",
      "iter 7450/10965\n",
      "iter 7500/10965\n",
      "iter 7550/10965\n",
      "iter 7600/10965\n",
      "iter 7650/10965\n",
      "iter 7700/10965\n",
      "iter 7750/10965\n",
      "iter 7800/10965\n",
      "iter 7850/10965\n",
      "iter 7900/10965\n",
      "iter 7950/10965\n",
      "iter 8000/10965\n",
      "iter 8050/10965\n",
      "iter 8100/10965\n",
      "iter 8150/10965\n",
      "iter 8200/10965\n",
      "iter 8250/10965\n",
      "iter 8300/10965\n",
      "iter 8350/10965\n",
      "iter 8400/10965\n",
      "iter 8450/10965\n",
      "iter 8500/10965\n",
      "iter 8550/10965\n",
      "iter 8600/10965\n",
      "iter 8650/10965\n",
      "iter 8700/10965\n",
      "iter 8750/10965\n",
      "iter 8800/10965\n",
      "iter 8850/10965\n",
      "iter 8900/10965\n",
      "iter 8950/10965\n",
      "iter 9000/10965\n",
      "iter 9050/10965\n",
      "iter 9100/10965\n",
      "iter 9150/10965\n",
      "iter 9200/10965\n",
      "iter 9250/10965\n",
      "iter 9300/10965\n",
      "iter 9350/10965\n",
      "iter 9400/10965\n",
      "iter 9450/10965\n",
      "iter 9500/10965\n",
      "iter 9550/10965\n",
      "iter 9600/10965\n",
      "iter 9650/10965\n",
      "iter 9700/10965\n",
      "iter 9750/10965\n",
      "iter 9800/10965\n",
      "iter 9850/10965\n",
      "iter 9900/10965\n",
      "iter 9950/10965\n",
      "iter 10000/10965\n",
      "iter 10050/10965\n",
      "iter 10100/10965\n",
      "iter 10150/10965\n",
      "iter 10200/10965\n",
      "iter 10250/10965\n",
      "iter 10300/10965\n",
      "iter 10350/10965\n",
      "iter 10400/10965\n",
      "iter 10450/10965\n",
      "iter 10500/10965\n",
      "iter 10550/10965\n",
      "iter 10600/10965\n",
      "iter 10650/10965\n",
      "iter 10700/10965\n",
      "iter 10750/10965\n",
      "iter 10800/10965\n",
      "iter 10850/10965\n",
      "iter 10900/10965\n",
      "iter 10950/10965\n"
     ]
    }
   ],
   "source": [
    "flist = load_files(\"attack_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_attack_or_health_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = load_files(\"anifood_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_anifood_training(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the NUMBS AI\n",
    "flist = load_files(\"numbs_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_numb_training2(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Situation AI\n",
    "flist = load_files(\"situation_training\")\n",
    "print(len(flist))\n",
    "X, y = gen_situation_training(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the WINS AI\n",
    "flist = load_files()\n",
    "print(len(flist))\n",
    "X, y = gen_training(flist, wins_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to WINS AI\n",
    "flist = load_files()\n",
    "print(len(flist))\n",
    "X, y = add_win_training(flist, wins_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some initial stats about X and y\n",
    "def print_counts(y):\n",
    "    vals, counts = np.unique(y, return_counts=True)\n",
    "    for val, count in zip(vals, counts):\n",
    "        print(f\"Val: {val}, Count: {count}\")\n",
    "\n",
    "# NOTE:\n",
    "# Weak number in NUMBS that need a boost!  i.e. < 60 examples\n",
    "# [0, 1, 2, 4, 5, 8, 11, 12, 13, 14]\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training data to disk\n",
    "\n",
    "ml_data = \"ml_data\"\n",
    "np.savetxt(os.path.join(ml_data, \"attack_x_train.txt\"), X)\n",
    "np.savetxt(os.path.join(ml_data, \"attack_y_train.txt\"), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION STUFFSSS\n",
    "\n",
    "model = LogisticRegression(multi_class=\"multinomial\", max_iter=400)\n",
    "solvers = ['lbfgs']\n",
    "penalty = ['l2']\n",
    "c_values = np.logspace(-2,0,5)\n",
    "\n",
    "# # define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=grid, \n",
    "    n_jobs=-1, \n",
    "    cv=cv, \n",
    "    scoring='accuracy',\n",
    "    error_score=0, \n",
    "    verbose=4,\n",
    ")\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means  = grid_result.cv_results_['mean_test_score']\n",
    "stds   = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "# Best: 0.998788 using {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "\n",
    "# L2_grid_search_df = pd.DataFrame.from_dict(grid_result.cv_results_)\n",
    "# L2_grid_search_df.to_csv(\"result_csvs/L2_grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=700)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model\n",
    "# X = np.loadtxt(os.path.join(\"ml_data\", \"wins_x_train.txt\"))\n",
    "# y = np.loadtxt(os.path.join(\"ml_data\", \"wins_y_train.txt\"))\n",
    "best_attack_model = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"lbfgs\",\n",
    "    C=0.01,\n",
    "    max_iter=700\n",
    "    )\n",
    "\n",
    "best_attack_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "result = best_attack_model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try MLP\n",
    "\n",
    "# Things to modify\n",
    "# * Alpha for sure\n",
    "# * Random state, since class\n",
    "# * Activation function \n",
    "\n",
    "# X = np.loadtxt(os.path.join(\"ml_data\", \"numbs_x_train.txt\"))\n",
    "# y = np.loadtxt(os.path.join(\"ml_data\", \"numbs_y_train.txt\"))\n",
    "\n",
    "# print_counts(y)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model         = MLPClassifier(max_iter=500)\n",
    "mlp_solver        = ['lbfgs']\n",
    "# mlp_random_states = [1,2,3,4,5]\n",
    "mlp_activation_functions = [\"logistic\", \"tanh\", \"relu\"]\n",
    "alphas = np.logspace(-2, 0, 5)\n",
    "\n",
    "# define grid search\n",
    "mlp_grid = dict(\n",
    "    solver=mlp_solver,\n",
    "    # random_state=mlp_random_states, \n",
    "    activation=mlp_activation_functions, \n",
    "    alpha=alphas, \n",
    ")\n",
    "mlp_cv          = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "mlp_grid_search = GridSearchCV(\n",
    "    estimator=mlp_model, \n",
    "    param_grid=mlp_grid, \n",
    "    n_jobs=-1, \n",
    "    cv=mlp_cv, \n",
    "    scoring='accuracy',\n",
    "    error_score=0,\n",
    "    verbose=4\n",
    ")\n",
    "mlp_grid_result = mlp_grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize results\n",
    "print(\"Best: %f using %s\" % (mlp_grid_result.best_score_, mlp_grid_result.best_params_))\n",
    "means  = mlp_grid_result.cv_results_['mean_test_score']\n",
    "stds   = mlp_grid_result.cv_results_['std_test_score']\n",
    "params = mlp_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.01, max_iter=500, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Final Best MLP Model\n",
    "# Best: 0.998788 using {'activation': 'logistic', 'alpha': 0.01, 'random_state': 1, 'solver': 'lbfgs'}\n",
    "\n",
    "best_attack_MLP = MLPClassifier(\n",
    "    activation   = \"logistic\",\n",
    "    alpha        = 0.01,\n",
    "    random_state = 1,\n",
    "    solver       = \"lbfgs\",\n",
    "    max_iter     = 500\n",
    "    )\n",
    "\n",
    "best_attack_MLP.fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = best_attack_MLP.score(X, y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = best_attack_MLP.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predy = best_attack_model.predict(X)\n",
    "\n",
    "for i, group in enumerate(zip(y, predy)):\n",
    "    if group[0] != group[1]:\n",
    "        print(f\"Pic #: {i}, Actual: {group[0]}, Pred: {group[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = os.path.join(\"models\", \"attack_MLP_model.02\")\n",
    "pickle.dump(best_attack_MLP, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X[0:100], y[:100])\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testx = np.loadtxt(os.path.join(\"ml_data\", \"numbs_x_train.txt\"))\n",
    "# testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GET COORDS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the coords for each attribute\n",
    "# find in specific order:\n",
    "# [coins, lives, wins, round]\n",
    "# info_img_dir = \"find_info_imgs\"\n",
    "\n",
    "# coins_file = os.path.join(info_img_dir, \"coins.png\")\n",
    "# lives_file = os.path.join(info_img_dir, \"lives.png\")\n",
    "# wins_file  = os.path.join(info_img_dir, \"wins.png\")\n",
    "# round_file = os.path.join(info_img_dir, \"round.png\")\n",
    "\n",
    "# base_file  = os.path.join(info_img_dir, \"base_w_squares.png\")\n",
    "\n",
    "# target_files = [coins_file, lives_file, wins_file, round_file]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i, t in enumerate(target_files):\n",
    "#     base_img = cv2.imread(base_file, cv2.COLOR_RGB2BGR)\n",
    "#     search_img = cv2.imread(t, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     if i != 2:\n",
    "#         w = NUM_CROP_W\n",
    "#         h = NUM_CROP_H\n",
    "#     else:\n",
    "#         w = ROUND_CROP_W\n",
    "#         h = ROUND_CROP_H\n",
    "\n",
    "#     a, b, c, best_match_xy = cv2.minMaxLoc(cv2.matchTemplate(base_img, search_img, cv2.TM_CCOEFF_NORMED))\n",
    "#     print(a, b, c, best_match_xy)\n",
    "#     cv2.rectangle(base_img, (best_match_xy[0], best_match_xy[1]), (best_match_xy[0] + w, best_match_xy[1] + h), (0,255,255), 2)\n",
    "#     show_cv2_img(\"bleh\", base_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(122, 116)\n",
    "(338, 116)\n",
    "(552, 116)\n",
    "(865, 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
